---
layout: post
title:  'Reading 12: Self-Driving Cars'
date:   2018-04-15 23:00:00 -0500
categories: jekyll update
---
Many motivations behind developing and building self-driving cars lie in making the road a safer place and making commutes for people quicker and more relaxing.  The AI software driving a car cannot get tired, it cannot get drunk, and it will not zone out for a second or text and drive.  This is safer, as long as the AI drives as good as or better than people, and the claims are that self-driving cars will be better than people, especially if the road only has only self-driving cars on it.  The communication between these cars is supposed to reduce traffic, making commutes quicker.  Someone can also eat, nap, and watch TV on their commute to work.  Another motivation is that the inventors of self-driving car technology want to line their pockets with the profits they will earn by being the first to develop this revolutionary technology.  Companies like Uber may have the interest of cutting the costs of the driver, who currently receives 80% of an Uber trip’s price, out of the picture.

I do not believe in the self-driving car hype.  At the very least, I think if all goes well for those developing them, they will still not be prominent for over forty years, with roads dominated by only self-driving vehicles a long way away after that.  I think that there are too many circumstances and edge cases for us to get fully autonomous cars to be a reality any sooner.  And these cars will not take over the road until the public is convinced they are safe.  The two recent fatalities in California and Arizona are the first of what will probably be many setbacks in convincing the public of this.  Think about when it snows and roads are half plowed.  Or an area susceptible to flooding after a lot of rain.  Or picking up someone from a hectic airport terminal and driving through Times Square.  It is going to be incredibly hard to make foolproof software that survives every condition.  Until then, we’ll need someone monitoring the car, and this may be better than someone entirely driving but they also may place too much trust in the car and become too easily distracted to react when needed.  The only way to know if self-driving car technology will pass these tests is to get them on road and to start learning about every scenario.  We are going to be stuck in a hybrid road situation with human drivers and AI together for a long time, and the full benefits of self-driving cars are not realized under these conditions.  Some stubborn people may never want to get into a self-driving car.  I think that other advances in the automation of public transportation or just new ideas related to transportation might become mainstream quicker than self-driving cars, decreasing the incentive to continue to make self-driving cars.

I do think perfect self-driving cars can make the road safer, but that is not in the near future.

The social dilemma of autonomous vehicles is tricky.  I would have to imagine that if the self-driving car is found to be the car that is responsible for an accident, the company that developed that car’s software must be held responsible.  This way, companies have a huge motivation to make these cars a crash-proof as possible. There is also the issue of who to kill when different courses of reaction can result in the death of different people, for example, the person in the car or a pedestrian.  Or if the car is on track to kill five people and instead can kill one. I honestly think what makes the most sense is for the car to do a calculation of which course of action is mostly likely to result in the least amount of death and injury and to follow that course of action.

One of the biggest social and political implications of self-driving cars is that they are meant to inevitably eliminate the jobs of people who currently drive for a living.  This will have to be handled just like any other job that becomes automated.  I do not think the government should put restrictions against self-driving cars because of this reason.  I do think the government needs to create safety standards for self-driving cars as well as assess if a self-driving car has an adequate reaction in a life or death scenario.

I do not think I’ll want a self-driving car.  Not until I have to own one, or until evidence is overwhelmingly in favor of them being safer.  I want to have control over my car.  I want to speed when I want to speed, I want to park where I want to park, and I want to know that the car is not going to fail on me because of an untested edge case.  
